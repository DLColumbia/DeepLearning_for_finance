{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are you on PC or MAC? pc = 0, mac = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computer = 0\n",
    "#! source activate tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import glob as glob\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "matplotlib.rcParams[ 'figure.figsize' ] = ( 14, 6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOTPATH = os.getcwd()\n",
    "path = os.path.join(ROOTPATH, 'Data')\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the file IBB_holdings.csv, the tickers are sorted by descending weigths as of 5-Feb-18\n",
    "# The file contains a lot of information about the fund IBB as of 5-Feb-18, which can be imported via row[i], i being the column you want\n",
    "# For now we only import the first column, tickers.\n",
    "\n",
    "if computer == 0:\n",
    "    with open('IBB_holdings.csv', 'r') as csvfile:\n",
    "        file = csv.reader(csvfile, delimiter=' ')\n",
    "        c=0\n",
    "        list_tickers=[]\n",
    "        for row in file:\n",
    "            if c >= 11:\n",
    "                list_tickers.append(row[0].split(',')[0])\n",
    "            c+=1\n",
    "else:\n",
    "    with open('IBB_holdings.csv', 'r', encoding ='mac_roman') as csvfile:\n",
    "        file = csv.reader(csvfile, delimiter=' ')\n",
    "        c=0\n",
    "        list_tickers=[]\n",
    "        for row in file:\n",
    "            if c >= 11:\n",
    "                list_tickers.append(row[0].split(',')[0])\n",
    "            c+=1\n",
    "            \n",
    "list_tickers.sort()\n",
    "list_tickers.pop()\n",
    "list_tickers.remove(\"BLKFDS\")\n",
    "list_tickers.remove(\"USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) We now want to download the data of all tickers as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up the variables\n",
    "\n",
    "start_date = '2016-01-01'\n",
    "end_date = '2018-01-01'\n",
    "\n",
    "\n",
    "nb_tickers = len(list_tickers)\n",
    "list_dataframes=[None]*(nb_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#On Yahoo\n",
    "still_missing = nb_tickers\n",
    "passages = 0\n",
    "\n",
    "while still_missing > 0 and passages < 100:\n",
    "    passages += 1\n",
    "    print(\"harvest number \" , passages)\n",
    "    for i in range (nb_tickers ):\n",
    "        if type(list_dataframes[i]) == type(None):   \n",
    "            symbol = list_tickers[i]\n",
    "            try:\n",
    "                df = web.DataReader(symbol, 'yahoo' , start_date ,end_date)\n",
    "                list_dataframes[i] = df\n",
    "                still_missing -= 1\n",
    "            except:\n",
    "                print(\"Oops!  That was no valid ticker.  Try again... \"+list_tickers[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Finally, we can download in a new folder all this information for future use, to avoid downloading them from the web again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Download of the dataframes as as many csv's (for now)\n",
    "\n",
    "for i in range (nb_tickers ):  \n",
    "    file_name = 'csv_' + list_tickers[i] + '_from_' + start_date + '_to_' + end_date + \".csv\"\n",
    "    string = path + '\\\\' + file_name\n",
    "    list_dataframes[i].to_csv(string , sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) This program is not (yet) collecting the two tickers that are not equities : BLKFDS and USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) We also need a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the benchmark is NASDAQ Biotechnology index \n",
    "symbol='^NBI'\n",
    "benchmark1 = web.DataReader(symbol, 'yahoo' , start_date ,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here the benchmark is iShares Nasdaq Biotechnology ETF \n",
    "symbol='IBB'\n",
    "benchmark2 = web.DataReader(symbol, 'yahoo' , start_date ,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Now we need rate of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ror_1 = benchmark1['High'].pct_change()\n",
    "df_ror_2 = benchmark2['High'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Both benchmarks should have similar rate of returns, though they have different prices\n",
    "plt.plot(df_ror_1)\n",
    "plt.hold\n",
    "plt.plot(df_ror_2)\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rateOfReturnWeekly(df,column):\n",
    "    # Column has to be a column of the dataframe (ie 'Open','AdjClose')\n",
    "    \n",
    "    # Making sure dataframe is well sorted\n",
    "    df_sorted = df.sort_index( ascending = True )\n",
    "    \n",
    "\n",
    "    # So far gives daily as shift = 1!\n",
    "    shift = 1\n",
    "    df_shifted = df_sorted.shift(shift)\n",
    "    rate_of_returns = (df_sorted - df_shifted) / df_shifted\n",
    "    rate_of_returns = rate_of_returns.drop(rate_of_returns.index[0])\n",
    "\n",
    "    return rate_of_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Function to add noise to a dataframe (a new dataframe will be created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise_2(df_origin, tick, mean = 0, std = 0.005):\n",
    "    noise = []\n",
    "    \n",
    "    # Creating the noise\n",
    "    for i in range(len(df_origin)):\n",
    "        x = np.exp(np.random.normal(mean,std))\n",
    "        noise.append(x)\n",
    "        \n",
    "    df_modified = df_origin.copy()\n",
    "    df_modified['Adj Close'] = df_modified['Adj Close'].multiply(noise)\n",
    "    \n",
    "    file_name = 'csv_' + tick + '_B_' + str(mean) + '_' + str(std) + '_from_' + start_date + '_to_' + end_date + '.csv'\n",
    "    string = path + file_name\n",
    "    df_modified.to_csv(os.path.join(path,file_name), sep=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Create all the new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "allFiles = glob.glob(path + \"/csv\" + \"*.csv\")\n",
    "\n",
    "\n",
    "i=0\n",
    "if computer == 0:\n",
    "    for file_ in allFiles:\n",
    "        with open(file_, 'r') as csvfile:\n",
    "            if list_tickers[i] != 'SNDX':\n",
    "                df = pd.read_csv(csvfile, index_col=None, header=0)\n",
    "                add_noise_2(df,list_tickers[i],0,0.01)\n",
    "                #add_noise_2(df,list_tickers[i],0,0.008)\n",
    "                #add_noise_2(df,list_tickers[i],0,0.0003)\n",
    "                #add_noise_2(df,list_tickers[i],0,0.002)\n",
    "                #add_noise_2(df,list_tickers[i],0,0.0006)\n",
    "            i=i+1\n",
    "    \n",
    "if computer == 1:    \n",
    "    for file_ in allFiles:\n",
    "        with open(file_, 'r', encoding ='mac_roman') as csvfile:\n",
    "            if list_tickers[i] != 'SNDX':\n",
    "                df = pd.read_csv(csvfile, index_col=None, header=0)\n",
    "                add_noise_2(df,list_tickers[i],0,0.01)\n",
    "                #add_noise_2(df,list_tickers[i],0,0.008)\n",
    "                #add_noise_2(df,list_tickers[i],0,0.0003)\n",
    "                #add_noise_2(df,list_tickers[i],0,0.002)\n",
    "                #add_noise_2(df,list_tickers[i],0,0.0006)\n",
    "            i=i+1\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
